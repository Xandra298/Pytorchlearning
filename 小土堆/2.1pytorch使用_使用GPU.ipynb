{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5a7acfb5",
   "metadata": {},
   "source": [
    "## 使用GPU"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9aaa9718",
   "metadata": {},
   "source": [
    "### 方式1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbc36a4e",
   "metadata": {},
   "source": [
    "将他们加载到GPU上，使用.cuda()\n",
    "- 网络模型\n",
    "- 数据\n",
    "- 损失函数\n",
    "\n",
    "具体见代码"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0f86f68c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import  torchvision\n",
    "from torch import nn\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from torch.utils.data import DataLoader\n",
    "import torch\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae910eb0",
   "metadata": {},
   "source": [
    "GPU训练\n",
    "\n",
    "可以看到时间比cpu快：\n",
    "\n",
    "cuda training\n",
    "----epoch 0 starting----\n",
    "time:1.1624798774719238\n",
    "\n",
    "batch 100---loss:2.2960407733917236\n",
    "time:2.374920606613159\n",
    "\n",
    "batch 200---loss:2.2844889163970947\n",
    "time:3.6774864196777344\n",
    "\n",
    "batch 300---loss:2.2557263374328613\n",
    "time:5.16971492767334\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9be8bacd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "训练数据集的长度为50000,测试数据集的长度为10000\n",
      "cuda training\n",
      "----epoch 0 starting----\n",
      "time:1.1624798774719238\n",
      "batch 100---loss:2.2960407733917236\n",
      "time:2.374920606613159\n",
      "batch 200---loss:2.2844889163970947\n",
      "time:3.6774864196777344\n",
      "batch 300---loss:2.2557263374328613\n",
      "time:5.16971492767334\n",
      "batch 400---loss:2.1544976234436035\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-14-6b9985880601>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     64\u001b[0m         \u001b[0mimgs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtargets\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     65\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_available\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 66\u001b[1;33m             \u001b[0mimgs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mimgs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     67\u001b[0m             \u001b[0mtargets\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtargets\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     68\u001b[0m         \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimgs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "##准备数据集\n",
    "train_data = torchvision.datasets.CIFAR10(\"../../dataset/\",train=True,transform=torchvision.transforms.ToTensor(),download=True)\n",
    "test_data = torchvision.datasets.CIFAR10(\"../../dataset/\",train=False,transform=torchvision.transforms.ToTensor(),download=True)\n",
    "\n",
    "#数据集长度\n",
    "train_data_size = len(train_data)\n",
    "test_data_size = len(test_data)\n",
    "\n",
    "print(\"训练数据集的长度为{},测试数据集的长度为{}\".format(train_data_size,test_data_size))\n",
    "\n",
    "##加载数据集\n",
    "train_dataloader = DataLoader(train_data,batch_size=64)\n",
    "test_dataloader = DataLoader(test_data,batch_size=64)\n",
    "\n",
    "##搭建神经网络\n",
    "class Model(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Model, self).__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Conv2d(3,32,5,1,2),\n",
    "            nn.MaxPool2d(2),\n",
    "            nn.Conv2d(32,32,5,1,2),\n",
    "            nn.MaxPool2d(2),\n",
    "            nn.Conv2d(32,64,5,1,2),\n",
    "            nn.MaxPool2d(2),\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(64*4*4,64),\n",
    "            nn.Linear(64,10)\n",
    "#             nn.Linear(64,10),\n",
    "#             nn.Softmax(dim=1)     ###其实softmax加上去结果很不好，反而原来的好\n",
    "        )\n",
    "    def forward(self,x):\n",
    "        x = self.model(x)\n",
    "        return x\n",
    "\n",
    "model  = Model()\n",
    "###############################################\n",
    "if torch.cuda.is_available():\n",
    "    print(\"cuda training\")\n",
    "    model = model.cuda()\n",
    "###############################################\n",
    "##损失函数\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "###############################################\n",
    "if torch.cuda.is_available():\n",
    "        loss_fn = loss_fn.cuda()\n",
    "###############################################\n",
    "##优化器\n",
    "learning_rate=1e-2\n",
    "optimizer = torch.optim.SGD(model.parameters(),lr=learning_rate)\n",
    "\n",
    "##设置训练网络的一些参数\n",
    "##记录训练的次数\n",
    "total_train_step= 0\n",
    "##记录测试的次数\n",
    "total_test_step =0\n",
    "##训练的轮数\n",
    "epoch=10\n",
    "##添加tensorboard\n",
    "start_time = time.time()\n",
    "for i in range(epoch):\n",
    "    print(\"----epoch {} starting----\".format(i))\n",
    "    model.train()\n",
    "    ##训练步骤开始\n",
    "    for data in train_dataloader:\n",
    "        imgs,targets = data\n",
    "        ###############################################\n",
    "        if torch.cuda.is_available():\n",
    "            imgs = imgs.cuda()\n",
    "            targets = targets.cuda()\n",
    "        ###############################################\n",
    "        outputs = model(imgs)\n",
    "        loss = loss_fn(outputs,targets)\n",
    "\n",
    "        ##优化器优化模型\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_train_step+=1\n",
    "        if total_train_step % 100 == 0:\n",
    "            end_time = time.time()\n",
    "            print(\"time:{}\".format(end_time-start_time))\n",
    "            print(\"batch {}---loss:{}\".format(total_train_step,loss.item()))\n",
    "    \n",
    "    ##测试\n",
    "    model.eval()\n",
    "    total_test_loss = 0\n",
    "    total_accuarcy = 0\n",
    "    \n",
    "    with torch.no_grad():##让网络模型无梯度\n",
    "        for data in test_dataloader:\n",
    "            imgs,targets = data\n",
    "            ###############################################\n",
    "            if torch.cuda.is_available():\n",
    "                imgs = imgs.cuda()\n",
    "                targets = targets.cuda()\n",
    "             ################################################   \n",
    "            outputs = model(imgs)\n",
    "            loss = loss_fn(outputs,targets)\n",
    "            total_test_loss+=loss\n",
    "            accuarcy = (outputs.argmax(1)==targets).sum()\n",
    "            total_accuarcy+=accuarcy\n",
    "    print(\"avarage testing loss:{}\".format(total_test_loss/test_data_size))\n",
    "    acc = total_accuarcy / test_data_size\n",
    "    print(\"acc:{}\".format(acc))\n",
    "    total_test_step+=1\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "116b0d6b",
   "metadata": {},
   "source": [
    "CPU训练\n",
    "\n",
    "time:5.044811487197876\n",
    "\n",
    "batch 100---loss:2.2861838340759277\n",
    "time:11.217432022094727\n",
    "\n",
    "batch 200---loss:2.282048463821411\n",
    "time:17.956006288528442\n",
    "\n",
    "batch 300---loss:2.2508111000061035\n",
    "time:24.85852336883545\n",
    "\n",
    "batch 400---loss:2.1681175231933594\n",
    "time:31.897176265716553"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e0846843",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "训练数据集的长度为50000,测试数据集的长度为10000\n",
      "----epoch 0 starting----\n",
      "time:5.044811487197876\n",
      "batch 100---loss:2.2861838340759277\n",
      "time:11.217432022094727\n",
      "batch 200---loss:2.282048463821411\n",
      "time:17.956006288528442\n",
      "batch 300---loss:2.2508111000061035\n",
      "time:24.85852336883545\n",
      "batch 400---loss:2.1681175231933594\n",
      "time:31.897176265716553\n",
      "batch 500---loss:2.035565137863159\n",
      "time:38.80791449546814\n",
      "batch 600---loss:2.0351269245147705\n",
      "time:45.61942219734192\n",
      "batch 700---loss:2.014039993286133\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-15-76b8621c10da>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     91\u001b[0m \u001b[1;31m#                 imgs = imgs.cuda()\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     92\u001b[0m \u001b[1;31m#                 targets = targets.cuda()\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 93\u001b[1;33m             \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimgs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     94\u001b[0m             \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtargets\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     95\u001b[0m             \u001b[0mtotal_test_loss\u001b[0m\u001b[1;33m+=\u001b[0m\u001b[0mloss\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\APP\\Anaconda\\envs\\Fpytorch\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    726\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 727\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[0;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-15-76b8621c10da>\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     31\u001b[0m         )\n\u001b[0;32m     32\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 33\u001b[1;33m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     34\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     35\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\APP\\Anaconda\\envs\\Fpytorch\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    726\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 727\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[0;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\APP\\Anaconda\\envs\\Fpytorch\\lib\\site-packages\\torch\\nn\\modules\\container.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    115\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    116\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 117\u001b[1;33m             \u001b[0minput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    118\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    119\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\APP\\Anaconda\\envs\\Fpytorch\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    726\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 727\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[0;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\APP\\Anaconda\\envs\\Fpytorch\\lib\\site-packages\\torch\\nn\\modules\\conv.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    421\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    422\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 423\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_conv_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    424\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    425\u001b[0m \u001b[1;32mclass\u001b[0m \u001b[0mConv3d\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_ConvNd\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\APP\\Anaconda\\envs\\Fpytorch\\lib\\site-packages\\torch\\nn\\modules\\conv.py\u001b[0m in \u001b[0;36m_conv_forward\u001b[1;34m(self, input, weight)\u001b[0m\n\u001b[0;32m    418\u001b[0m                             _pair(0), self.dilation, self.groups)\n\u001b[0;32m    419\u001b[0m         return F.conv2d(input, weight, self.bias, self.stride,\n\u001b[1;32m--> 420\u001b[1;33m                         self.padding, self.dilation, self.groups)\n\u001b[0m\u001b[0;32m    421\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    422\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "##准备数据集\n",
    "train_data = torchvision.datasets.CIFAR10(\"../../dataset/\",train=True,transform=torchvision.transforms.ToTensor(),download=True)\n",
    "test_data = torchvision.datasets.CIFAR10(\"../../dataset/\",train=False,transform=torchvision.transforms.ToTensor(),download=True)\n",
    "\n",
    "#数据集长度\n",
    "train_data_size = len(train_data)\n",
    "test_data_size = len(test_data)\n",
    "\n",
    "print(\"训练数据集的长度为{},测试数据集的长度为{}\".format(train_data_size,test_data_size))\n",
    "\n",
    "##加载数据集\n",
    "train_dataloader = DataLoader(train_data,batch_size=64)\n",
    "test_dataloader = DataLoader(test_data,batch_size=64)\n",
    "\n",
    "##搭建神经网络\n",
    "class Model(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Model, self).__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Conv2d(3,32,5,1,2),\n",
    "            nn.MaxPool2d(2),\n",
    "            nn.Conv2d(32,32,5,1,2),\n",
    "            nn.MaxPool2d(2),\n",
    "            nn.Conv2d(32,64,5,1,2),\n",
    "            nn.MaxPool2d(2),\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(64*4*4,64),\n",
    "            nn.Linear(64,10)\n",
    "#             nn.Linear(64,10),\n",
    "#             nn.Softmax(dim=1)     ###其实softmax加上去结果很不好，反而原来的好\n",
    "        )\n",
    "    def forward(self,x):\n",
    "        x = self.model(x)\n",
    "        return x\n",
    "\n",
    "model  = Model()\n",
    "# if torch.cuda.is_available():\n",
    "#     print(\"cuda training\")\n",
    "#     model = model.cuda()\n",
    "##损失函数\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "# if torch.cuda.is_available():\n",
    "#         loss_fn = loss_fn.cuda()\n",
    "\n",
    "##优化器\n",
    "learning_rate=1e-2\n",
    "optimizer = torch.optim.SGD(model.parameters(),lr=learning_rate)\n",
    "\n",
    "##设置训练网络的一些参数\n",
    "##记录训练的次数\n",
    "total_train_step= 0\n",
    "##记录测试的次数\n",
    "total_test_step =0\n",
    "##训练的轮数\n",
    "epoch=10\n",
    "##添加tensorboard\n",
    "start_time = time.time()\n",
    "for i in range(epoch):\n",
    "    print(\"----epoch {} starting----\".format(i))\n",
    "    model.train()\n",
    "    ##训练步骤开始\n",
    "    for data in train_dataloader:\n",
    "        imgs,targets = data\n",
    "#         if torch.cuda.is_available():\n",
    "#             imgs = imgs.cuda()\n",
    "#             targets = targets.cuda()\n",
    "        outputs = model(imgs)\n",
    "        loss = loss_fn(outputs,targets)\n",
    "\n",
    "        ##优化器优化模型\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_train_step+=1\n",
    "        if total_train_step % 100 == 0:\n",
    "            end_time = time.time()\n",
    "            print(\"time:{}\".format(end_time-start_time))\n",
    "            print(\"batch {}---loss:{}\".format(total_train_step,loss.item()))\n",
    "    \n",
    "    ##测试\n",
    "    model.eval()\n",
    "    total_test_loss = 0\n",
    "    total_accuarcy = 0\n",
    "    \n",
    "    with torch.no_grad():##让网络模型无梯度\n",
    "        for data in test_dataloader:\n",
    "            imgs,targets = data\n",
    "#             if torch.cuda.is_available():\n",
    "#                 imgs = imgs.cuda()\n",
    "#                 targets = targets.cuda()\n",
    "            outputs = model(imgs)\n",
    "            loss = loss_fn(outputs,targets)\n",
    "            total_test_loss+=loss\n",
    "            accuarcy = (outputs.argmax(1)==targets).sum()\n",
    "            total_accuarcy+=accuarcy\n",
    "    print(\"avarage testing loss:{}\".format(total_test_loss/test_data_size))\n",
    "    acc = total_accuarcy / test_data_size\n",
    "    print(\"acc:{}\".format(acc))\n",
    "    total_test_step+=1\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88fc03d9",
   "metadata": {},
   "source": [
    "### 通用方式2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ace9621",
   "metadata": {},
   "source": [
    "首先定义device\n",
    "\n",
    "然后使用.to(device)在：\n",
    "\n",
    "    - 模型\n",
    "    - 数据，标注\n",
    "    - 损失函数\n",
    "    \n",
    "注意数据和标注需要赋值，而模型和损失函数并不是必须：\n",
    "\n",
    "    如 model.to(device)即可，不用model = model.to(device)；但是数据和label记得要"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a33aaf1",
   "metadata": {},
   "source": [
    "####  device定义方式\n",
    "1. cpu\n",
    "2. GPU:cuda  / 多张GPU\n",
    "3. 通用定义"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29d9cf15",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11369263",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\")\n",
    "\n",
    "device = torch.device(\"cuda:0\")##有多张显卡时对应特定显卡序号"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7259212",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7304f10",
   "metadata": {},
   "source": [
    "#### 具体代码测试"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ec1aa3dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "训练数据集的长度为50000,测试数据集的长度为10000\n",
      "----epoch 0 starting----\n",
      "time:25.88600754737854\n",
      "batch 200---loss:2.289736270904541\n",
      "avarage testing loss:0.017700864002108574\n",
      "acc:0.15429998934268951\n",
      "----epoch 1 starting----\n",
      "time:45.108107566833496\n",
      "batch 400---loss:2.2158942222595215\n",
      "time:58.37624406814575\n",
      "batch 600---loss:2.0101733207702637\n",
      "avarage testing loss:0.015590372495353222\n",
      "acc:0.28839999437332153\n",
      "----epoch 2 starting----\n",
      "time:73.59836173057556\n",
      "batch 800---loss:2.040374994277954\n",
      "time:86.32196187973022\n",
      "batch 1000---loss:1.9103964567184448\n",
      "avarage testing loss:0.01465497724711895\n",
      "acc:0.35109999775886536\n",
      "----epoch 3 starting----\n",
      "time:99.13157439231873\n",
      "batch 1200---loss:1.853210210800171\n",
      "time:108.50026369094849\n",
      "batch 1400---loss:1.736275553703308\n",
      "avarage testing loss:0.01404686737805605\n",
      "acc:0.37389999628067017\n",
      "----epoch 4 starting----\n",
      "time:121.19837546348572\n",
      "batch 1600---loss:1.7123537063598633\n",
      "time:130.442889213562\n",
      "batch 1800---loss:1.7215958833694458\n",
      "avarage testing loss:0.013187231495976448\n",
      "acc:0.4057999849319458\n",
      "----epoch 5 starting----\n",
      "time:142.59665703773499\n",
      "batch 2000---loss:1.552221417427063\n",
      "time:151.84209299087524\n",
      "batch 2200---loss:1.532063603401184\n",
      "avarage testing loss:0.012613259255886078\n",
      "acc:0.43309998512268066\n",
      "----epoch 6 starting----\n",
      "time:165.23900413513184\n",
      "batch 2400---loss:1.682148814201355\n",
      "time:175.08574104309082\n",
      "batch 2600---loss:1.4875651597976685\n",
      "avarage testing loss:0.012343189679086208\n",
      "acc:0.45170000195503235\n",
      "----epoch 7 starting----\n",
      "time:188.26340889930725\n",
      "batch 2800---loss:1.496668815612793\n",
      "time:199.64431977272034\n",
      "batch 3000---loss:1.7130467891693115\n",
      "avarage testing loss:0.011972691863775253\n",
      "acc:0.4681999981403351\n",
      "----epoch 8 starting----\n",
      "time:211.5107717514038\n",
      "batch 3200---loss:1.3730531930923462\n",
      "time:221.62099623680115\n",
      "batch 3400---loss:1.4091893434524536\n",
      "avarage testing loss:0.01154770515859127\n",
      "acc:0.48649999499320984\n",
      "----epoch 9 starting----\n",
      "time:234.60988879203796\n",
      "batch 3600---loss:1.378293514251709\n",
      "time:245.645015001297\n",
      "batch 3800---loss:1.3843247890472412\n",
      "avarage testing loss:0.011169936507940292\n",
      "acc:0.50409996509552\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\")\n",
    "\n",
    "\n",
    "##准备数据集\n",
    "train_data = torchvision.datasets.CIFAR10(\"../../dataset/\",train=True,transform=torchvision.transforms.ToTensor(),download=True)\n",
    "test_data = torchvision.datasets.CIFAR10(\"../../dataset/\",train=False,transform=torchvision.transforms.ToTensor(),download=True)\n",
    "\n",
    "#数据集长度\n",
    "train_data_size = len(train_data)\n",
    "test_data_size = len(test_data)\n",
    "\n",
    "print(\"训练数据集的长度为{},测试数据集的长度为{}\".format(train_data_size,test_data_size))\n",
    "\n",
    "##加载数据集\n",
    "train_dataloader = DataLoader(train_data,batch_size=128)\n",
    "test_dataloader = DataLoader(test_data,batch_size=128)\n",
    "\n",
    "##搭建神经网络\n",
    "class Model(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Model, self).__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Conv2d(3,32,5,1,2),\n",
    "            nn.MaxPool2d(2),\n",
    "            nn.Conv2d(32,32,5,1,2),\n",
    "            nn.MaxPool2d(2),\n",
    "           \n",
    "            nn.Conv2d(32,64,5,1,2),\n",
    "            nn.MaxPool2d(2),\n",
    "#             nn.ReLU(),\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(64*4*4,64),\n",
    "            nn.Linear(64,10)\n",
    "#             nn.Linear(64,10),\n",
    "#             nn.Softmax(dim=1)     ###其实softmax加上去结果很不好，反而原来的好\n",
    "        )\n",
    "    def forward(self,x):\n",
    "        x = self.model(x)\n",
    "        return x\n",
    "\n",
    "model  = Model()\n",
    "model  = model.to(device)\n",
    "##损失函数\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "loss_fn = loss_fn.to(device)\n",
    "##优化器\n",
    "learning_rate=1e-2\n",
    "optimizer = torch.optim.SGD(model.parameters(),lr=learning_rate)\n",
    "\n",
    "##设置训练网络的一些参数\n",
    "##记录训练的次数\n",
    "total_train_step= 0\n",
    "##记录测试的次数\n",
    "total_test_step =0\n",
    "##训练的轮数\n",
    "epoch=10\n",
    "##添加tensorboard\n",
    "start_time = time.time()\n",
    "for i in range(epoch):\n",
    "    print(\"----epoch {} starting----\".format(i))\n",
    "    model.train()\n",
    "    ##训练步骤开始\n",
    "    for data in train_dataloader:\n",
    "        imgs,targets = data\n",
    "        imgs = imgs.to(device)\n",
    "        targets = targets.to(device)\n",
    "        outputs = model(imgs)\n",
    "        loss = loss_fn(outputs,targets)\n",
    "\n",
    "        ##优化器优化模型\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_train_step+=1\n",
    "        if total_train_step % 200 == 0:\n",
    "            end_time = time.time()\n",
    "            print(\"time:{}\".format(end_time-start_time))\n",
    "            print(\"batch {}---loss:{}\".format(total_train_step,loss.item()))\n",
    "    \n",
    "    ##测试\n",
    "    model.eval()\n",
    "    total_test_loss = 0\n",
    "    total_accuarcy = 0\n",
    "    \n",
    "    with torch.no_grad():##让网络模型无梯度\n",
    "        for data in test_dataloader:\n",
    "            imgs,targets = data\n",
    "            imgs = imgs.to(device)\n",
    "            targets = targets.to(device)\n",
    "            outputs = model(imgs)\n",
    "            loss = loss_fn(outputs,targets)\n",
    "            total_test_loss+=loss\n",
    "            accuarcy = (outputs.argmax(1)==targets).sum()\n",
    "            total_accuarcy+=accuarcy\n",
    "    print(\"avarage testing loss:{}\".format(total_test_loss/test_data_size))\n",
    "    acc = total_accuarcy / test_data_size\n",
    "    print(\"acc:{}\".format(acc))\n",
    "    total_test_step+=1\n",
    "    \n",
    "torch.save(model,\"../../model_10.pth\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c65e47b",
   "metadata": {},
   "source": [
    "### 查看机器上显卡"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a3bdbb6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thu Oct 13 11:28:44 2022       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 471.41       Driver Version: 471.41       CUDA Version: 11.4     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name            TCC/WDDM | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  NVIDIA GeForce ... WDDM  | 00000000:01:00.0 Off |                  N/A |\n",
      "| N/A   67C    P0    N/A /  N/A |    619MiB /  2048MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|    0   N/A  N/A      8792      C   ...\\envs\\Fpytorch\\python.exe    N/A      |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
