{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c7f06e9b",
   "metadata": {},
   "source": [
    "### 准备数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "533f7a1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "训练数据集的长度为50000,测试数据集的长度为10000\n"
     ]
    }
   ],
   "source": [
    "import  torchvision\n",
    "from torch import nn\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "\n",
    "##准备数据集\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "train_data = torchvision.datasets.CIFAR10(\"../../dataset/\",train=True,transform=torchvision.transforms.ToTensor(),download=True)\n",
    "test_data = torchvision.datasets.CIFAR10(\"../../dataset/\",train=False,transform=torchvision.transforms.ToTensor(),download=True)\n",
    "\n",
    "#数据集长度\n",
    "train_data_size = len(train_data)\n",
    "test_data_size = len(test_data)\n",
    "\n",
    "print(\"训练数据集的长度为{},测试数据集的长度为{}\".format(train_data_size,test_data_size))\n",
    "\n",
    "##加载数据集\n",
    "train_dataloader = DataLoader(train_data,batch_size=64)\n",
    "test_dataloader = DataLoader(test_data,batch_size=64)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2b42a30",
   "metadata": {},
   "source": [
    "### 创建模型"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e51c50c",
   "metadata": {},
   "source": [
    "搭建模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7d2ea85d",
   "metadata": {},
   "outputs": [],
   "source": [
    "##搭建神经网络\n",
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "\n",
    "class Model(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Model, self).__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Conv2d(3,32,5,1,2),\n",
    "            nn.MaxPool2d(2),\n",
    "            nn.Conv2d(32,32,5,1,2),\n",
    "            nn.MaxPool2d(2),\n",
    "            nn.Conv2d(32,64,5,1,2),\n",
    "            nn.MaxPool2d(2),\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(64*4*4,64),\n",
    "            nn.Linear(64,10)\n",
    "#             nn.Linear(64,10),\n",
    "#             nn.Softmax(dim=1)     ###其实softmax加上去结果很不好，反而原来的好\n",
    "        )\n",
    "    def forward(self,x):\n",
    "        x = self.model(x)\n",
    "        return x\n",
    "\n",
    "# if __name__ == '__main__':\n",
    "#     ##对model的输入输出做一个验证\n",
    "#     model = Model()\n",
    "#     input = torch.ones(64,3,32,32)\n",
    "#     output = model(input)\n",
    "#     print(output.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42e12494",
   "metadata": {},
   "source": [
    "调用创建模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "825a958c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model  = Model()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ec748d9",
   "metadata": {},
   "source": [
    "### 训练"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79e5d048",
   "metadata": {},
   "source": [
    "一些参数设置：损失函数与优化器"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "869d7765",
   "metadata": {},
   "outputs": [],
   "source": [
    "##损失函数\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "##优化器\n",
    "learning_rate=1e-2\n",
    "optimizer = torch.optim.SGD(model.parameters(),lr=learning_rate)\n",
    "\n",
    "##设置训练网络的一些参数\n",
    "##记录训练的次数\n",
    "total_train_step= 0\n",
    "##记录测试的次数\n",
    "total_test_step =0\n",
    "##训练的轮数\n",
    "epoch=10\n",
    "##添加tensorboard\n",
    "writer = SummaryWriter(\"../../logs_train\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a09424c",
   "metadata": {},
   "source": [
    "训练与评估"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "4b306d5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----epoch 0 starting----\n",
      "batch 100---loss:1.2290760278701782\n",
      "batch 200---loss:1.3597694635391235\n",
      "batch 300---loss:1.4100321531295776\n",
      "batch 400---loss:1.310434341430664\n",
      "batch 500---loss:1.267032265663147\n",
      "batch 600---loss:1.4049432277679443\n",
      "batch 700---loss:1.5253032445907593\n",
      "avarage testing loss:0.02288610301911831\n",
      "acc:0.4722000062465668\n",
      "模型已保存\n",
      "----epoch 1 starting----\n",
      "batch 800---loss:1.1795254945755005\n",
      "batch 900---loss:1.2778332233428955\n",
      "batch 1000---loss:1.2601470947265625\n",
      "batch 1100---loss:1.4348729848861694\n",
      "batch 1200---loss:1.1991231441497803\n",
      "batch 1300---loss:1.1737687587738037\n",
      "batch 1400---loss:1.2603963613510132\n",
      "batch 1500---loss:1.2066330909729004\n",
      "avarage testing loss:0.021816112101078033\n",
      "acc:0.4975999891757965\n",
      "模型已保存\n",
      "----epoch 2 starting----\n",
      "batch 1600---loss:1.1059505939483643\n",
      "batch 1700---loss:1.1840121746063232\n",
      "batch 1800---loss:1.3561244010925293\n",
      "batch 1900---loss:1.3754281997680664\n",
      "batch 2000---loss:1.5921956300735474\n",
      "batch 2100---loss:0.9712749719619751\n",
      "batch 2200---loss:0.9969114661216736\n",
      "batch 2300---loss:1.2670338153839111\n",
      "avarage testing loss:0.020700054243206978\n",
      "acc:0.5277000069618225\n",
      "模型已保存\n",
      "----epoch 3 starting----\n",
      "batch 2400---loss:1.2204596996307373\n",
      "batch 2500---loss:1.0257823467254639\n",
      "batch 2600---loss:1.2528949975967407\n",
      "batch 2700---loss:1.1823859214782715\n",
      "batch 2800---loss:1.1907774209976196\n",
      "batch 2900---loss:1.2905092239379883\n",
      "batch 3000---loss:1.009425401687622\n",
      "batch 3100---loss:1.2194753885269165\n",
      "avarage testing loss:0.019966915249824524\n",
      "acc:0.546500027179718\n",
      "模型已保存\n",
      "----epoch 4 starting----\n",
      "batch 3200---loss:0.968138575553894\n",
      "batch 3300---loss:1.046433448791504\n",
      "batch 3400---loss:1.0497549772262573\n",
      "batch 3500---loss:1.1416985988616943\n",
      "batch 3600---loss:1.1686785221099854\n",
      "batch 3700---loss:1.0355702638626099\n",
      "batch 3800---loss:1.189873456954956\n",
      "batch 3900---loss:1.1658871173858643\n",
      "avarage testing loss:0.019573332741856575\n",
      "acc:0.557699978351593\n",
      "模型已保存\n",
      "----epoch 5 starting----\n",
      "batch 4000---loss:1.1101807355880737\n",
      "batch 4100---loss:1.24716317653656\n",
      "batch 4200---loss:1.2769235372543335\n",
      "batch 4300---loss:0.9827172756195068\n",
      "batch 4400---loss:0.8029163479804993\n",
      "batch 4500---loss:1.2220557928085327\n",
      "batch 4600---loss:1.119246006011963\n",
      "avarage testing loss:0.019198400899767876\n",
      "acc:0.5672000050544739\n",
      "模型已保存\n",
      "----epoch 6 starting----\n",
      "batch 4700---loss:0.9113446474075317\n",
      "batch 4800---loss:1.2315281629562378\n",
      "batch 4900---loss:1.1590768098831177\n",
      "batch 5000---loss:1.12830650806427\n",
      "batch 5100---loss:0.8307771682739258\n",
      "batch 5200---loss:1.0602351427078247\n",
      "batch 5300---loss:0.8411788940429688\n",
      "batch 5400---loss:0.9792308211326599\n",
      "avarage testing loss:0.018811218440532684\n",
      "acc:0.5752999782562256\n",
      "模型已保存\n",
      "----epoch 7 starting----\n",
      "batch 5500---loss:0.975691556930542\n",
      "batch 5600---loss:0.8972184658050537\n",
      "batch 5700---loss:0.8922903537750244\n",
      "batch 5800---loss:0.8409563899040222\n",
      "batch 5900---loss:1.1151398420333862\n",
      "batch 6000---loss:1.2539840936660767\n",
      "batch 6100---loss:0.8398503065109253\n",
      "batch 6200---loss:0.8601300716400146\n",
      "avarage testing loss:0.018435729667544365\n",
      "acc:0.5849000215530396\n",
      "模型已保存\n",
      "----epoch 8 starting----\n",
      "batch 6300---loss:1.1039726734161377\n",
      "batch 6400---loss:0.9189684391021729\n",
      "batch 6500---loss:1.3556163311004639\n",
      "batch 6600---loss:0.8550615310668945\n",
      "batch 6700---loss:0.8700377345085144\n",
      "batch 6800---loss:0.9092372059822083\n",
      "batch 6900---loss:0.8218596577644348\n",
      "batch 7000---loss:0.5739513635635376\n",
      "avarage testing loss:0.01802961900830269\n",
      "acc:0.597100019454956\n",
      "模型已保存\n",
      "----epoch 9 starting----\n",
      "batch 7100---loss:0.9052830338478088\n",
      "batch 7200---loss:0.7690684795379639\n",
      "batch 7300---loss:0.9771405458450317\n",
      "batch 7400---loss:0.7491801977157593\n",
      "batch 7500---loss:0.9005227088928223\n",
      "batch 7600---loss:1.0588880777359009\n",
      "batch 7700---loss:0.692557692527771\n",
      "batch 7800---loss:1.1722335815429688\n",
      "avarage testing loss:0.017707347869873047\n",
      "acc:0.6057000160217285\n",
      "模型已保存\n"
     ]
    }
   ],
   "source": [
    "for i in range(epoch):\n",
    "    print(\"----epoch {} starting----\".format(i))\n",
    "    model.train()\n",
    "    ##训练步骤开始\n",
    "    for data in train_dataloader:\n",
    "        imgs,targets = data\n",
    "        outputs = model(imgs)\n",
    "        loss = loss_fn(outputs,targets)\n",
    "\n",
    "        ##优化器优化模型\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_train_step+=1\n",
    "        if total_train_step % 100 == 0:\n",
    "           print(\"batch {}---loss:{}\".format(total_train_step,loss.item()))\n",
    "            #tensorboard展示\n",
    "           writer.add_scalar(\"train_loss\",loss.item(),total_train_step)\n",
    "    \n",
    "    \n",
    "    ##测试\n",
    "    model.eval()\n",
    "    total_test_loss = 0\n",
    "    total_accuarcy = 0\n",
    "    \n",
    "    with torch.no_grad():##让网络模型无梯度\n",
    "        for data in test_dataloader:\n",
    "            imgs,targets = data\n",
    "            outputs = model(imgs)\n",
    "            loss = loss_fn(outputs,targets)\n",
    "            total_test_loss+=loss\n",
    "            accuarcy = (outputs.argmax(1)==targets).sum()\n",
    "            total_accuarcy+=accuarcy\n",
    "    print(\"avarage testing loss:{}\".format(total_test_loss/test_data_size))\n",
    "    acc = total_accuarcy / test_data_size\n",
    "    print(\"acc:{}\".format(acc))\n",
    "    total_test_step+=1\n",
    "    #tensorboard展示\n",
    "    writer.add_scalar(\"test_loss\",total_test_loss/test_data_size,total_test_step)\n",
    "    writer.add_scalar(\"test_acc\",acc,total_test_step)\n",
    "    \n",
    "    \n",
    "#保存模型\n",
    "    # torch.save(model,\"model_{}.pth\".format(i))\n",
    "    # print(\"模型已保存\")\n",
    "    torch.save(model.state_dict(),\"../../model_{}.pth\".format(i))\n",
    "    print(\"模型已保存\")\n",
    "    \n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b26223c4",
   "metadata": {},
   "source": [
    "注意：\n",
    "\n",
    "model.train()\n",
    "\n",
    "model.eval()\n",
    "\n",
    "在实际的train和evaluation之前不写不影响平时的训练与评估\n",
    "\n",
    "他们的作用只会作用于特定的神经网络层"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bb8f3d6",
   "metadata": {},
   "source": [
    "### 无关：其他无关的一些代码测试"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac8e09e3",
   "metadata": {},
   "source": [
    "softmax的一点测试"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "49f9e74e",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 3])\n",
      "tensor([[ 0.4819,  0.8810,  0.4999],\n",
      "        [ 0.0394, -1.5907, -0.8583]])\n",
      "tensor([[0.2850, 0.4248, 0.2902],\n",
      "        [0.6237, 0.1222, 0.2542]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "m = nn.Softmax(dim=1)\n",
    "input = torch.randn(2, 3)\n",
    "print(input.shape)\n",
    "print(input)\n",
    "output = m(input)\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bf030db0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 3])\n",
      "tensor([[ 0.4819,  0.8810,  0.4999],\n",
      "        [ 0.0394, -1.5907, -0.8583]])\n",
      "tensor([[0.2850, 0.4248, 0.2902],\n",
      "        [0.6237, 0.1222, 0.2541]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\34860\\AppData\\Roaming\\Python\\Python37\\site-packages\\ipykernel_launcher.py:8: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "m = nn.Softmax()\n",
    "input = torch.tensor([[ 0.4819,  0.8810,  0.4999],\n",
    "        [ 0.0394, -1.5907, -0.8583]])\n",
    "print(input.shape)\n",
    "print(input)\n",
    "output = m(input)\n",
    "print(output)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
